{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK2TBoSN9leM"
      },
      "source": [
        "# 准备数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKnf7IdCPyWs",
        "outputId": "e4a87a05-3bbd-4c7b-c1b1-5e2b50421e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-18 10:30:37--  https://github.com/YoungY620/neu-lung2022/releases/download/v0.4/data.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/484630425/22b90c27-0b7b-484d-8b32-6acd2bd0885d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220518%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220518T103038Z&X-Amz-Expires=300&X-Amz-Signature=e9db79e34141c920cf376569e14ca4d9e8624cd7e3d6d80a0e92d6360a4e50c9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=484630425&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-05-18 10:30:38--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/484630425/22b90c27-0b7b-484d-8b32-6acd2bd0885d?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220518%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220518T103038Z&X-Amz-Expires=300&X-Amz-Signature=e9db79e34141c920cf376569e14ca4d9e8624cd7e3d6d80a0e92d6360a4e50c9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=484630425&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 112435672 (107M) [application/octet-stream]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 107.23M  32.2MB/s    in 3.3s    \n",
            "\n",
            "2022-05-18 10:30:41 (32.2 MB/s) - ‘data.zip’ saved [112435672/112435672]\n",
            "\n",
            "--2022-05-18 10:30:41--  https://github.com/YoungY620/neu-lung2022/releases/download/v0.4/models.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/484630425/a30bfebc-2e1f-4e0b-be96-9bd97ffa2120?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220518%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220518T103041Z&X-Amz-Expires=300&X-Amz-Signature=1a2f1e47908cb2348821060eec445321e57b803bb1abf95330b8c65c962c4f17&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=484630425&response-content-disposition=attachment%3B%20filename%3Dmodels.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-05-18 10:30:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/484630425/a30bfebc-2e1f-4e0b-be96-9bd97ffa2120?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220518%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220518T103041Z&X-Amz-Expires=300&X-Amz-Signature=1a2f1e47908cb2348821060eec445321e57b803bb1abf95330b8c65c962c4f17&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=484630425&response-content-disposition=attachment%3B%20filename%3Dmodels.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 141956923 (135M) [application/octet-stream]\n",
            "Saving to: ‘models.zip’\n",
            "\n",
            "models.zip          100%[===================>] 135.38M  26.6MB/s    in 5.7s    \n",
            "\n",
            "2022-05-18 10:30:47 (23.8 MB/s) - ‘models.zip’ saved [141956923/141956923]\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "wget -O data.zip https://github.com/YoungY620/neu-lung2022/releases/download/v0.4/data.zip\n",
        "wget -O models.zip https://github.com/YoungY620/neu-lung2022/releases/download/v0.4/models.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIjpNVZn9q8w",
        "outputId": "3ac0d632-9104-429d-d2af-74f9ce53a830"
      },
      "outputs": [
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "rm -rf ./data ./simclr_images\n",
        "unzip -qn ./data.zip -d data\n",
        "unzip -qn ./models.zip\n",
        "\n",
        "cp -rf ./data/images ./simclr_images\n",
        "# unzip -h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9K8LUWTAFic"
      },
      "source": [
        "# 训练特征提取\n",
        "\n",
        "使用 SImCLR\n",
        "\n",
        "除了原本图像的三通道，还增加了边缘检测特征，通过1*1卷积映射到三通道\n",
        "\n",
        "数据是没有任何标签的图片\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYiqSADBG4zK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def get_filelist(dir):\n",
        "  flist = []\n",
        "  for home, dirs, files in os.walk(dir):\n",
        "    for filename in files:\n",
        "      # if filename.split(\"-\")[1] == \"100\":\n",
        "        flist.append(os.path.join(home, filename))\n",
        "  return flist\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-eZoCGvWMHp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.transforms import transforms\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "class GaussianBlur(object):\n",
        "  \"\"\"\n",
        "  blur a single image on CPU\n",
        "  \"\"\"\n",
        "  def __init__(self, kernel_size):\n",
        "    radias = kernel_size // 2\n",
        "    kernel_size = radias * 2 + 1\n",
        "    self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n",
        "                            stride=1, padding=0, bias=False, groups=3)\n",
        "    self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n",
        "                            stride=1, padding=0, bias=False, groups=3)\n",
        "    self.k = kernel_size\n",
        "    self.r = radias\n",
        "\n",
        "    self.blur = nn.Sequential(\n",
        "        nn.ReflectionPad2d(radias),\n",
        "        self.blur_h,\n",
        "        self.blur_v\n",
        "    )\n",
        "\n",
        "    self.pil_to_tensor = transforms.ToTensor()\n",
        "    self.tensor_to_pil = transforms.ToPILImage()\n",
        "\n",
        "  def __call__(self, img):\n",
        "    img = self.pil_to_tensor(img).unsqueeze(0)\n",
        "\n",
        "    sigma = np.random.uniform(0.1, 2.0)\n",
        "    x = np.arange(-self.r, self.r + 1)\n",
        "    x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n",
        "    x = x / x.sum()\n",
        "    x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n",
        "\n",
        "    self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n",
        "    self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img = self.blur(img)\n",
        "        img = img.squeeze()\n",
        "\n",
        "    img = self.tensor_to_pil(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "class AddCannyEdgeLayer(object):\n",
        "  def __init__(self, threadhold1, threadhold2):\n",
        "    self.th1 = threadhold1\n",
        "    self.th2 = threadhold2\n",
        "\n",
        "  def __call__(self, img: Image):\n",
        "    _img = np.array(img.convert('L'))\n",
        "    edge = cv.Canny(_img, 100, 200)[:, :, None]\n",
        "    # print(img.shape, _img.shape, edge.shape)\n",
        "    img = np.append(img, edge, axis=-1)\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "117IyDlnYXgG"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLearningViewGenerator(object):\n",
        "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
        "\n",
        "    def __init__(self, base_transform, n_views=2):\n",
        "        self.base_transform = base_transform\n",
        "        self.n_views = n_views\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return [self.base_transform(x) for i in range(self.n_views)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "Pn5Ba_7cOMR_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# import cv2 as cv\n",
        "\n",
        "# img = cv.imread(\"/content/unlabeled/105-100-1.jpg\", 0)\n",
        "# edges = cv.Canny(img,50,200)\n",
        "\n",
        "# # plt.figure(figsize=(60, 8))\n",
        "# # plt.subplot(211),plt.imshow(img, cmap = 'gray')\n",
        "# # plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
        "# # plt.subplot(212),plt.imshow(edges, cmap = 'gray')\n",
        "# # plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
        "\n",
        "# print(np.array(Image.open('/content/unlabeled/105-100-1.jpg').convert('RGB')).shape, img.shape)\n",
        "# Image.fromarray(img.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Stv-DF6SNPf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "class ContrastiveLearningDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, data_root, n_views) -> None:\n",
        "    transforms = self.get_simclr_pipeline_transform(80)\n",
        "    self.transforms = ContrastiveLearningViewGenerator(transforms, n_views)\n",
        "\n",
        "    flist = get_filelist(data_root)\n",
        "    self.img_boxes = []\n",
        "    h, w, _ = np.array(Image.open(flist[0])).shape\n",
        "    for f in flist:\n",
        "      for xmin, ymin in zip(range(0, h, h//8), range(0, w, w//8)):\n",
        "        img = Image.open(f).crop((xmin, ymin, xmin+h/8, ymin+w/8)).convert(\"RGB\")\n",
        "        self.img_boxes.append((f, img))\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.img_boxes)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    imfile, img = self.img_boxes[idx]\n",
        "\n",
        "    if self.transforms != None:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "  @staticmethod\n",
        "  def get_simclr_pipeline_transform(size, s=1):\n",
        "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "\n",
        "    trans = [transforms.RandomResizedCrop(size=size),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomApply([color_jitter], p=0.8),\n",
        "          transforms.RandomGrayscale(p=0.2),\n",
        "          GaussianBlur(kernel_size=int(0.1 * size)),\n",
        "          AddCannyEdgeLayer(50, 200),\n",
        "          transforms.ToTensor()]\n",
        "    \n",
        "    data_transforms = transforms.Compose(trans)\n",
        "    return data_transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApEjs1fbXDUJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import yaml\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "\n",
        "def save_config_file(model_checkpoints_folder, args):\n",
        "    if not os.path.exists(model_checkpoints_folder):\n",
        "        os.makedirs(model_checkpoints_folder)\n",
        "        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n",
        "            yaml.dump(args, outfile, default_flow_style=False)\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ9pSD-Ff5YS"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ResNetSimCLR(nn.Module):\n",
        "\n",
        "    def __init__(self, base_model, out_dim):\n",
        "        super(ResNetSimCLR, self).__init__()\n",
        "        self.resnet_dict = {\"resnet18\": models.resnet18(pretrained=False, num_classes=out_dim),\n",
        "                            \"resnet50\": models.resnet50(pretrained=False, num_classes=out_dim)}\n",
        "\n",
        "        self.backbone = self._get_basemodel(base_model)\n",
        "        dim_mlp = self.backbone.fc.in_features\n",
        "\n",
        "        # add mlp projection head\n",
        "        self.backbone.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.backbone.fc)\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(4, 3, kernel_size=1),\n",
        "            self.backbone\n",
        "        )\n",
        "\n",
        "    def _get_basemodel(self, model_name):\n",
        "        try:\n",
        "            model = self.resnet_dict[model_name]\n",
        "        except KeyError:\n",
        "            raise NotImplementedError(\n",
        "                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n",
        "        else:\n",
        "            return model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WYRysRKWmsH"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "\n",
        "class SimCLR(object):\n",
        "\n",
        "    def __init__(self, model, optimizer, scheduler, **kw):\n",
        "        self.args = kw\n",
        "\n",
        "        self.model = model.to(self.args['device'])\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.log_dir = self.args['log_dir']\n",
        "        # self.writer = SummaryWriter()\n",
        "        \n",
        "        if 'resume' in self.args.keys() and self.args['resume']:\n",
        "          assert 'resume_model_path' in self.args.keys()\n",
        "          checkpoint = torch.load(self.args['resume_model_path'], map_location=self.args['device'])\n",
        "          state_dict = checkpoint['state_dict']\n",
        "          model.load_state_dict(state_dict)\n",
        "\n",
        "        logging.basicConfig(\n",
        "            filename=os.path.join(self.log_dir, 'training.log'), \n",
        "            level=logging.DEBUG)\n",
        "        \n",
        "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args['device'])\n",
        "        self.evals = {}\n",
        "    \n",
        "    def _push_eval(self, ekey, eidx, eval):\n",
        "      if ekey not in self.evals.keys():\n",
        "        self.evals[ekey] = ([],[])\n",
        "      self.evals[ekey][0].append(eidx)\n",
        "      self.evals[ekey][1].append(eval)\n",
        "\n",
        "    def _get_last_eval(self, ekey):\n",
        "      if ekey not in self.evals.keys():\n",
        "        return -1\n",
        "      return self.evals[ekey][1][-1]\n",
        "\n",
        "    def get_eval(self, ekey):\n",
        "      return self.evals[ekey]\n",
        "\n",
        "    def info_nce_loss(self, features):\n",
        "\n",
        "        labels = torch.cat([torch.arange(self.args['batch_size']) for i in range(self.args['n_views'])], dim=0)\n",
        "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
        "        labels = labels.to(self.args['device'])\n",
        "\n",
        "        features = F.normalize(features, dim=1)\n",
        "\n",
        "        similarity_matrix = torch.matmul(features, features.T)\n",
        "        # assert similarity_matrix.shape == (\n",
        "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
        "        # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "        # discard the main diagonal from both: labels and similarities matrix\n",
        "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args['device'])\n",
        "        labels = labels[~mask].view(labels.shape[0], -1)\n",
        "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
        "        # assert similarity_matrix.shape == labels.shape\n",
        "\n",
        "        # select and combine multiple positives\n",
        "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
        "\n",
        "        # select only the negatives the negatives\n",
        "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
        "\n",
        "        logits = torch.cat([positives, negatives], dim=1)\n",
        "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args['device'])\n",
        "\n",
        "        logits = logits / self.args['temperature']\n",
        "        return logits, labels\n",
        "\n",
        "    def train(self, train_loader):\n",
        "\n",
        "        scaler = GradScaler(enabled=self.args['fp16_precision'])\n",
        "\n",
        "        # save config file\n",
        "        save_config_file(self.log_dir, self.args)\n",
        "\n",
        "        n_iter = 0\n",
        "        logging.info(f\"Start SimCLR training for {self.args['epochs']} epochs.\")\n",
        "        logging.info(f\"Training with gpu: {self.args['enable_cuda']}.\")\n",
        "\n",
        "        for epoch_counter in range(self.args['epochs']):\n",
        "            cus_bar_format = '[Epoch:{:4d}]'.format(epoch_counter)\n",
        "            cus_bar_format += '{l_bar}{bar}{r_bar}' \n",
        "            cus_bar_format += f\"Step:{n_iter}\\t Loss:{self._get_last_eval('loss'):.4f}\\t acc/total:{self._get_last_eval('acc/total'):.2f} acc/top1:{self._get_last_eval('acc/top1'):.2f}\\t acc/top5:{self._get_last_eval('acc/top5'):.2f}\\t learning_rate:{self.scheduler.get_lr()[0]}\"\n",
        "            for images in tqdm(train_loader, bar_format=cus_bar_format):\n",
        "                images = torch.cat(images, dim=0)\n",
        "\n",
        "                images = images.to(self.args['device'])\n",
        "\n",
        "                with autocast(enabled=self.args['fp16_precision']):\n",
        "                    features = self.model(images)\n",
        "                    logits, labels = self.info_nce_loss(features)\n",
        "                    loss = self.criterion(logits, labels)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "\n",
        "                scaler.step(self.optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                if n_iter % self.args['log_every_n_steps'] == 0:\n",
        "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
        "                    logging.debug(f\"Step: {n_iter}\\tLoss: {loss}\\t acc/top1: {top1[0]}\\t acc/top5: {top5[0]}\\t learning_rate: {self.scheduler.get_lr()[0]}\")\n",
        "\n",
        "                    self._push_eval('loss', int(n_iter), float(loss.cpu()))\n",
        "                    self._push_eval('acc/top1', int(n_iter), float(top1[0].cpu()))\n",
        "                    self._push_eval('acc/top5', int(n_iter), float(top5[0].cpu()))\n",
        "                    self._push_eval('learning_rate', int(n_iter), float(self.scheduler.get_lr()[0]))\n",
        "\n",
        "                n_iter += 1\n",
        "\n",
        "            # warmup for the first 10 epochs\n",
        "            if epoch_counter >= 10:\n",
        "                self.scheduler.step()\n",
        "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0].cpu()}\")\n",
        "            self._push_eval('acc/total', int(n_iter), top1[0])\n",
        "\n",
        "        logging.info(\"Training has finished.\")\n",
        "        # save model checkpoints\n",
        "        checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(self.args['epochs'])\n",
        "        save_checkpoint({\n",
        "            'epoch': self.args['epochs'],\n",
        "            'arch': self.args['arch'],\n",
        "            'state_dict': self.model.state_dict(),\n",
        "            'optimizer': self.optimizer.state_dict(),\n",
        "        }, is_best=False, filename=os.path.join(self.log_dir, checkpoint_name))\n",
        "        logging.info(f\"Model checkpoint and metadata has been saved at {self.log_dir}.\")\n",
        "\n",
        "        for name, vdict in self.evals.items():\n",
        "          name_ = name.replace('/', '-')\n",
        "          filename = os.path.join(self.log_dir, f'{name_}.csv')\n",
        "          with open(filename, mode='w') as fobj:\n",
        "            for i, v in zip(vdict[0], vdict[1]):\n",
        "              fobj.write(f'{i:d},{v:f}\\n')\n",
        "        logging.info(f\"Model evals has been saved at {self.log_dir}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZxMykeGXLA2",
        "outputId": "92faffb3-6520-4dc5-ec0a-96041f36fc28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import models\n",
        "\n",
        "batch_size = 50\n",
        "n_view = 2\n",
        "\n",
        "# check if gpu training is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    cudnn.deterministic = True\n",
        "    cudnn.benchmark = True\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "dataset = ContrastiveLearningDataset('./simclr_images', n_view)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=batch_size, shuffle=True,\n",
        "    num_workers=2, pin_memory=True, drop_last=True)\n",
        "\n",
        "model = ResNetSimCLR(base_model=\"resnet18\", out_dim=64)\n",
        "\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.00006, weight_decay=1e-4)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0, last_epoch=-1)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.2, last_epoch=-1)\n",
        "\n",
        "args = {\n",
        "    'device': device,\n",
        "    'batch_size': batch_size,\n",
        "    'temperature': 0.07,\n",
        "    'fp16_precision': True,\n",
        "    'log_every_n_steps': 100,\n",
        "    'save_every_n_epochs': 50,\n",
        "    'epochs': 2000 if False else 0,    # 仅模型评估，设为 0\n",
        "    # 'epochs':0,\n",
        "    'arch': 'resnet18',\n",
        "    'enable_cuda' : torch.cuda.is_available(),\n",
        "    'n_views': n_view, \n",
        "    'resume':False, \n",
        "    'resume_model_path': './checkpoint_0200.pth.tar',\n",
        "    'log_dir': './'\n",
        "}\n",
        "\n",
        "simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, **args)\n",
        "simclr.train(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j6qbuuOTW8t"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# import datetime\n",
        "\n",
        "# plt.figure(0)\n",
        "# plt.plot(simclr.get_eval('loss')[0], simclr.get_eval('loss')[1])\n",
        "# f = plt.gcf()  \n",
        "# f.savefig(f'./loss.png')\n",
        "# f.clear()  \n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XVEirO-pN0T"
      },
      "source": [
        "# 实验使用训练好的编码器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyYMbmzkBwHI"
      },
      "source": [
        "## 准备 带标签的 bounding box 数据，同时将数据转化为本地文件格式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDAjiyjppTh5",
        "outputId": "ed5bbd67-5297-447e-c922-49e8a23f78e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 166 kB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 61.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 31.9 MB/s \n",
            "\u001b[?25h  Building wheel for pygeotile (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \"labelbox[data]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3FGNupcpgrC"
      },
      "outputs": [],
      "source": [
        "from labelbox import Client, OntologyBuilder\n",
        "from labelbox.data.annotation_types import Geometry\n",
        "from labelbox.data.annotation_types.collection import LabelList\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu6pEirnpkBj"
      },
      "outputs": [],
      "source": [
        "class SegClsName:\n",
        "  VESSEL = \"血管\"\n",
        "  BRONCHUS = \"支气管\"\n",
        "\n",
        "  def get_all_names():\n",
        "    return ['支气管', '血管']\n",
        "\n",
        "class VesselRatingName:\n",
        "  D = \"D血管周围浸润\"\n",
        "\n",
        "class BronchusRatingName:\n",
        "  A = \"A支气管浸润\"\n",
        "  B = \"B支气管浸润定性\"\n",
        "  C = \"C支气管腔渗出\"\n",
        "\n",
        "  def get_all_names():\n",
        "    return [\"A支气管浸润\", \"B支气管浸润定性\", \"C支气管腔渗出\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFo8AzAFpmlS",
        "outputId": "f3234472-982b-40b2-c5e2-59ac3f963d6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/labelbox/data/annotation_types/classification/classification.py:85: UserWarning: Dropdown classification is deprecated and will be removed in a future release\n",
            "  warnings.warn(\"Dropdown classification is deprecated and will be \"\n"
          ]
        }
      ],
      "source": [
        "API_KEY = \"your-key\"\n",
        "PROJECT_ID = \"your-id\"\n",
        "client = Client(api_key=API_KEY)\n",
        "project = client.get_project(PROJECT_ID)\n",
        "labels = project.label_generator().as_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcissylomjel"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from threading import Thread\n",
        "\n",
        "def get_box(a):\n",
        "  mask = a.value.draw()[:, :, 0]\n",
        "  pos = np.where(mask != 0)\n",
        "  xmin = np.min(pos[1])\n",
        "  xmax = np.max(pos[1])\n",
        "  ymin = np.min(pos[0])\n",
        "  ymax = np.max(pos[0])\n",
        "  # 只针对 ResNet18 的约束\n",
        "  # if xmax - xmin > 32 or ymax - ymin > 32: \n",
        "  return [xmin, ymin, xmax, ymax] \n",
        "  # return None\n",
        "\n",
        "def data_enhance(bs, rs):\n",
        "  data_dict = {}\n",
        "  for b,r in zip(bs, rs):\n",
        "    if r not in data_dict.keys(): data_dict[r] = []\n",
        "    data_dict[r].append(b)\n",
        "  ctr = Counter(rs)\n",
        "  max_num = max(list(ctr.values()))\n",
        "  for r in data_dict.keys():\n",
        "    if ctr[r] >= max_num: continue\n",
        "    bs.extend(np.random.choice(data_dict[r], size=max_num-ctr[r]))\n",
        "    rs.extend([r] * (max_num - ctr[r]))\n",
        "    assert len(bs)==len(rs)\n",
        "\n",
        "def get_box_ratings(lb_labels: LabelList, cls_name, rating_name, n_workers=4, balance=False):\n",
        "\n",
        "  boxes = []\n",
        "  ratings = []\n",
        "\n",
        "  def parse(lb, a):\n",
        "    if a.name != cls_name: return\n",
        "    rating = [float(c.value.answer.name) for c in a.classifications if c.name == rating_name]\n",
        "    if len(rating) == 0: return\n",
        "    rating = rating[0]\n",
        "    box = get_box(a)\n",
        "    if box == None: return\n",
        "    im = lb.data.value[box[1]:box[3]+1, box[0]:box[2]+1]\n",
        "    \n",
        "    boxes.append(im)\n",
        "    ratings.append(rating)\n",
        "\n",
        "  class ParsingThread(Thread):\n",
        "    def __init__(self, lb, a):\n",
        "      Thread.__init__(self)\n",
        "      self.lb = lb\n",
        "      self.a = a\n",
        "\n",
        "    def run(self):\n",
        "      parse(self.lb, self.a)\n",
        "\n",
        "  ths = []\n",
        "  for lb in lb_labels:\n",
        "    for a in lb.object_annotations():\n",
        "      ths.append(ParsingThread(lb, a))\n",
        "\n",
        "  for t in ths[:n_workers]: t.start()\n",
        "  for t1, t2 in zip(ths, ths[n_workers:]):\n",
        "    t1.join()\n",
        "    t2.start()\n",
        "  for t in ths[-n_workers:]: t.join()\n",
        "\n",
        "  if balance: data_enhance(boxes, ratings)\n",
        "\n",
        "  boxes = [Image.fromarray(im) for im in boxes]\n",
        "  return boxes, np.array(ratings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrFpBO4AxrBa"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import transforms as T\n",
        "\n",
        "def get_transform():\n",
        "    transforms = [\n",
        "        T.Resize((80, 80)),\n",
        "        AddCannyEdgeLayer(50, 200), \n",
        "        T.ToTensor()\n",
        "    ]\n",
        "    # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    return T.Compose(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aInsFEaOGPLX",
        "outputId": "dfa44440-fe9a-4f3b-b3e8-ab4ff5bd9d2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<labelbox.data.annotation_types.collection.LabelList at 0x7fa71115e790>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_e_ratings(lb_labels):\n",
        "  imgs = []\n",
        "  ratings = []\n",
        "  for lb in lb_labels:\n",
        "    if len(lb.classification_annotations()) != 0:\n",
        "      imgs.append(Image.fromarray(lb.data.value))\n",
        "      ratings.append(float(lb.classification_annotations()[0].value.answer.name))\n",
        "  return imgs, np.array(ratings)\n",
        "\n",
        "# labels[0].classification_annotations()[0].value.answer.name\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-KjlUYAFL5D"
      },
      "outputs": [],
      "source": [
        "X_, Y = get_box_ratings(labels, SegClsName.VESSEL, VesselRatingName.D, n_workers=8)\n",
        "# X_, Y = get_e_ratings(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZTIEzszn70SN",
        "outputId": "a7d3f4f6-fe48-49db-af8b-1380d23c8c8e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2-100-1.jpg'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(labels[0].data.external_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGPSvgOO7YzT"
      },
      "outputs": [],
      "source": [
        "file_names = []\n",
        "boxes = []\n",
        "a, b, c = [], [], []\n",
        "for lb in labels:\n",
        "  for ann in lb.object_annotations():\n",
        "    if ann.name != SegClsName.BRONCHUS: continue\n",
        "    boxes.append(get_box(ann))\n",
        "    file_names.append(lb.data.external_id)\n",
        "    aa, bb, cc = None, None, None\n",
        "    for cls in ann.classifications:\n",
        "      if cls.name == BronchusRatingName.A: \n",
        "        aa = (float(cls.value.answer.name))\n",
        "      if cls.name == BronchusRatingName.B: \n",
        "        bb = (float(cls.value.answer.name))\n",
        "      if cls.name == BronchusRatingName.C: \n",
        "        cc = (float(cls.value.answer.name))\n",
        "    a.append(aa)\n",
        "    b.append(bb)\n",
        "    c.append(cc)\n",
        "import pandas as pd\n",
        "boxes = np.array([[b for b in bb] for bb in boxes])\n",
        "df = pd.DataFrame(data={\"file_name\":file_names, \"xmin\": boxes[:,0], \"ymin\":boxes[:,1], \"xmax\":boxes[:,2], \"ymax\":boxes[:,3], \"a\":a, \"b\":b, \"c\":c})\n",
        "df.to_csv(\"./bronchus.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySbTSZWZF7kW",
        "outputId": "fa838108-7c95-4cdf-e525-e93dd0812ab2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['file_name', 'xmin', 'ymin', 'xmax', 'ymax', 'd'], dtype='object')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_names = []\n",
        "boxes = []\n",
        "d = []\n",
        "for lb in labels:\n",
        "  for ann in lb.object_annotations():\n",
        "    if ann.name != SegClsName.VESSEL: continue\n",
        "    if len(ann.classifications) != 0:\n",
        "      file_names.append(lb.data.external_id)\n",
        "      boxes.append(get_box(ann))\n",
        "      d.append(float(ann.classifications[0].value.answer.name))\n",
        "\n",
        "import pandas as pd\n",
        "boxes = np.array([[b for b in bb] for bb in boxes])\n",
        "df = pd.DataFrame(data={\"file_name\":file_names, \"xmin\": boxes[:,0], \"ymin\":boxes[:,1], \"xmax\":boxes[:,2], \"ymax\":boxes[:,3], \"d\":d})\n",
        "df.to_csv(\"./vessel.csv\")\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy2cLWnLOxFu",
        "outputId": "da0bc447-f5b0-4976-9de3-0053c0d2dab4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['a', 'b', 'c'], dtype='object')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(columns=['file_name', 'xmin', 'ymin', 'xmax',  'a', 'b', 'c']).columns.difference(df.columns)\n",
        "# df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeObHYOtS2TV",
        "outputId": "c601251e-dd17-4d8f-814e-36e31cdd9ebe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['file_name', 'ymin', 'xmax', 'x']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = ['file_name', 'ymin', 'xmax' ]\n",
        "a+[\"x\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NFubcRnpHJ7I",
        "outputId": "266df56d-0bf2-42ce-95bc-5339c6deb248"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-31abab34-5061-4457-a081-3ef4891dbf5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>e</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2-100-1.jpg</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1-100-3.jpg</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2-100-2.jpg</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1-100-2.jpg</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3-100-1.jpg</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>84-100-2.jpg</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>84-100-3.jpg</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>85-100-1.jpg</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>85-100-2.jpg</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>85-100-3.jpg</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>103 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31abab34-5061-4457-a081-3ef4891dbf5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31abab34-5061-4457-a081-3ef4891dbf5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31abab34-5061-4457-a081-3ef4891dbf5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        file_name    e\n",
              "0     2-100-1.jpg  3.0\n",
              "1     1-100-3.jpg  1.0\n",
              "2     2-100-2.jpg  3.0\n",
              "3     1-100-2.jpg  2.0\n",
              "4     3-100-1.jpg  1.0\n",
              "..            ...  ...\n",
              "98   84-100-2.jpg  1.0\n",
              "99   84-100-3.jpg  0.0\n",
              "100  85-100-1.jpg  4.0\n",
              "101  85-100-2.jpg  1.0\n",
              "102  85-100-3.jpg  4.0\n",
              "\n",
              "[103 rows x 2 columns]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_names = []\n",
        "boxes = []\n",
        "e = []\n",
        "for lb in labels:\n",
        "  if len(lb.classification_annotations()) != 0:\n",
        "    file_names.append(lb.data.external_id)\n",
        "    e.append(float(lb.classification_annotations()[0].value.answer.name))\n",
        "\n",
        "import pandas as pd\n",
        "boxes = np.array([[b for b in bb] for bb in boxes])\n",
        "df = pd.DataFrame(data={\"file_name\":file_names, \"e\":e})\n",
        "df.to_csv(\"./overall.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hinRKnppBSuC",
        "outputId": "c0de6460-fac8-49c2-f1a9-6467bd0944f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((0,), 3, 110, 110, 103)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# boxes = [[b for b in bb] for bb in boxes]\n",
        "boxes.shape, len(a), len(b), len(c), len(file_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5TvtWsWl4qQ"
      },
      "source": [
        "## 利用简单的回归模型给出评分 并保存模型参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOpuFox_JuLJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def get_rating_data(index):\n",
        "    data_dir = \"./data/images\"\n",
        "    if index in ['a', 'b', 'c']:\n",
        "        df = pd.read_csv(\"./data/bronchus.csv\")\n",
        "    elif index in ['d']:\n",
        "        df = pd.read_csv(\"./data/vessel.csv\")\n",
        "    else:\n",
        "        df = pd.read_csv(\"./data/overall.csv\")\n",
        "    pil_images, ratings = [], []\n",
        "    assert index in ['a', 'b', 'c', 'd', 'e'] and index in df.columns\n",
        "    df = df.dropna(subset=[index])\n",
        "    filename = None\n",
        "    img = None\n",
        "    for i, row in df.iterrows():\n",
        "        if row[index] == None: continue\n",
        "        if row['file_name'] != filename:\n",
        "            img = Image.open(os.path.join(\n",
        "                data_dir, row['file_name'])).convert(\"RGB\")\n",
        "        ratings.append(row[index])\n",
        "        if index == 'e':\n",
        "            pil_images.append(img)\n",
        "        else:\n",
        "            pil_images.append(img.crop((row['xmin'], row['ymin'], row['xmax'], row['ymax'])))\n",
        " \n",
        "    return pil_images, ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rodtzP_RvUat"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "import cv2 as cv\n",
        "import pywt\n",
        "import pywt.data\n",
        "\n",
        "_m = ResNetSimCLR('resnet18',64)\n",
        "checkpoint = torch.load('./simclr_encoder.pth.tar', map_location=device)\n",
        "state_dict = checkpoint['state_dict']\n",
        "_m.load_state_dict(state_dict)\n",
        "def get_feature_model(train=False): \n",
        "  if not train: _m.eval()\n",
        "  else: _m.train()\n",
        "  return _m\n",
        "\n",
        "def remove_unnecessary_region(mask):\n",
        "  mask = np.array(mask)\n",
        "  edge_unique = np.unique(mask[[0,-1],:][:,[0,-1]])[1:]\n",
        "  for i in edge_unique:\n",
        "    mask[np.where(mask==i)] = 0\n",
        "  return mask\n",
        "\n",
        "def get_area(img, histfile='nucleus.npy', remove_unnecessary=False):\n",
        "  hist = np.load(histfile)\n",
        "  hsvt = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
        "  dst = cv.calcBackProject([hsvt], [0, 1], hist, [0, 180, 0, 256], 1)\n",
        "\n",
        "  # Now convolute with circular disc\n",
        "  disc = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
        "  cv.filter2D(dst, -1, disc, dst)\n",
        "\n",
        "  # threshold and binary AND\n",
        "  ret, thresh = cv.threshold(dst, 0, 255, 0)\n",
        "  thresh = cv.merge((thresh, thresh, thresh))\n",
        "  if remove_unnecessary:\n",
        "    thresh = remove_unnecessary_region(thresh)\n",
        "  return np.where(thresh[:,:,0])[0].shape[0]\n",
        "\n",
        "def get_nucleus_area(img, remove_unnecessary=False):\n",
        "  return get_area(img, '/content/drive/MyDrive/nucleus.npy', remove_unnecessary)\n",
        "\n",
        "def get_cytoplasm_area(img, remove_unnecessary=False):\n",
        "  return get_area(img, '/content/drive/MyDrive/cytoplasm.npy', remove_unnecessary)\n",
        "\n",
        "def get_background_area(img, remove_unnecessary=False):\n",
        "  return get_area(img, '/content/drive/MyDrive/background.npy', remove_unnecessary)\n",
        "\n",
        "def get_flatten_rating_feature(im, index, transforms, remove_unnecessary=False):\n",
        "  net = get_feature_model()\n",
        "  im = im.convert('RGB')\n",
        "  \n",
        "  ftr = []\n",
        "  # 抽象特征\n",
        "  tensor_im = transforms(im.copy()).unsqueeze(0).to(device)\n",
        "  ftr = np.append(ftr, np.array(net(tensor_im).cpu().detach()).flatten())\n",
        "\n",
        "  grey_im = np.array(im.copy().convert('L'))\n",
        "\n",
        "  # # 像素特征\n",
        "  # ftr = np.append(ftr, np.array(im.copy().resize((200, 200))).flatten(), axis=0)\n",
        "\n",
        "  # 灰度共存矩阵\n",
        "  compress_gray = np.digitize(grey_im, np.linspace(0, 255, 64))\n",
        "  comatrix = greycomatrix(compress_gray, np.linspace(10, 20, num=4), \n",
        "                [0, np.pi / 4, np.pi / 2, np.pi * 3 / 4],\n",
        "                256, symmetric=True, normed=True)\n",
        "  for prop in {'contrast', 'dissimilarity','homogeneity', 'energy', 'correlation', 'ASM'}:\n",
        "    temp = greycoprops(comatrix, prop).flatten()\n",
        "    ftr = np.append(ftr, temp, axis=0)\n",
        "\n",
        "  # 小波包变换能量系数\n",
        "  # n_level = 3\n",
        "  # re = []  #第n层所有节点的分解系数\n",
        "  # wp = pywt.WaveletPacket2D(data=grey_im, wavelet='db1',mode='symmetric',maxlevel=n_level)\n",
        "  # for p in [n.path for nodes in wp.get_level(n_level, 'freq') for n in nodes]:\n",
        "  #   ftr = np.append(ftr, np.array([float(pow(np.linalg.norm(wp[p].data,ord=None),2))]), axis=0)\n",
        "\n",
        "  # 细胞核占比与空洞占比（颜色特征）\n",
        "  n_area = get_nucleus_area(np.array(im.copy()), remove_unnecessary)\n",
        "  c_area = get_cytoplasm_area(np.array(im.copy()), remove_unnecessary)\n",
        "  b_area = get_background_area(np.array(im.copy()), remove_unnecessary)\n",
        "  ftr = np.append(ftr, np.array([n_area/c_area]))\n",
        "  ftr = np.append(ftr, np.array([b_area/c_area]))\n",
        "  \n",
        "  \n",
        "  return ftr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlthT5HnJPBk"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import KBinsDiscretizer, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import joblib\n",
        "\n",
        "def try_one_batch(tr_x, te_x, tr_y, te_y, save=False,save_name='./vot_reg.pk'):\n",
        "  svr_boost = AdaBoostRegressor(base_estimator=SVR(C=1.0, epsilon=0.2), \n",
        "                                n_estimators=1\n",
        "                                )\n",
        "  tr_pip = Pipeline([('discretizer', KBinsDiscretizer(n_bins=5, encode=\"onehot\", strategy='uniform')), \n",
        "          ('tree',DecisionTreeRegressor(max_depth=5))])\n",
        "  tree_boost = AdaBoostRegressor(base_estimator=tr_pip, \n",
        "                                #  n_estimators=10\n",
        "                                 ) \n",
        "  # poly_pip = Pipeline([('poly', PolynomialFeatures(degree=3)),\n",
        "  #             ('linear', LinearRegression(fit_intercept=False))])\n",
        "  # poly_boost = AdaBoostRegressor(base_estimator=poly_pip)\n",
        "  estimators = [\n",
        "    ('svr', svr_boost), \n",
        "    # ('tree', tree_boost)\n",
        "  ]\n",
        "\n",
        "  stk_reg = StackingRegressor(estimators=estimators, final_estimator=MLPRegressor(random_state=1, max_iter=500))\n",
        "  vot_reg = make_pipeline(SelectKBest(f_regression, k=90), VotingRegressor(estimators=estimators))\n",
        "\n",
        "  vot_reg.fit(tr_x, tr_y)         # 全部特征\n",
        "  test_s, train_s = vot_reg.score(te_x, te_y),vot_reg.score(tr_x, tr_y)\n",
        "  print(test_s, train_s)\n",
        "\n",
        "  # stk_reg.fit(tr_x, tr_y)         # 全部特征\n",
        "  # test_s, train_s = stk_reg.score(te_x, te_y),stk_reg.score(tr_x, tr_y)\n",
        "  # print(test_s, train_s)\n",
        "\n",
        "  if save:\n",
        "    # joblib.dump(vot_reg, './stk_reg.pk')\n",
        "    joblib.dump(vot_reg, save_name)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvd-inBXLW3u"
      },
      "source": [
        "0.1724523568400822 0.7844490754454692\n",
        "\n",
        "0.20146480960616187 0.8291754094070458"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MqokGXFQm1r",
        "outputId": "5a2add3c-5dbf-49d1-d5d7-622892982505"
      },
      "outputs": [
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "rm -f *.pk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDbeBSLSQYvh",
        "outputId": "2e96b0f5-d3fd-4fdb-8c78-21c68bc46869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.01642341356082133 0.09892584316369124\n",
            "0.024804514020629664 0.12347674859747271\n",
            "0.04091714187476103 0.13523702339052612\n",
            "-0.015257752414766124 0.04884885946888229\n",
            "-0.08929590398661791 -0.029944410723651282\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "for ind in ['a', 'b','c','d','e']:\n",
        "  X_, Y = get_rating_data('a')\n",
        "  X = np.array([get_flatten_rating_feature(im, 'a', get_transform()) for im in X_])\n",
        "\n",
        "  X.shape, np.array(Y).shape\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=49, test_size=0.2)\n",
        "  try_one_batch(X_train, X_test, y_train, y_test, save=True, save_name=f\"vot_reg_{ind}.pk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1sC1WTqRa_C",
        "outputId": "bead7333-d926-4d1e-e0e1-41210aa802f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: vot_reg_a.pk (deflated 41%)\n",
            "  adding: vot_reg_b.pk (deflated 32%)\n",
            "  adding: vot_reg_c.pk (deflated 31%)\n",
            "  adding: vot_reg_d.pk (deflated 38%)\n",
            "  adding: vot_reg_e.pk (deflated 33%)\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%shell\n",
        "rm -f augmented.zip\n",
        "zip -rr augmented.zip *.pk"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "simclr--neu-lung.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
